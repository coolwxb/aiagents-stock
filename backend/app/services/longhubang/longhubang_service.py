"""
æ™ºç°é¾™è™ç»¼åˆåˆ†æå¼•æ“
æ•´åˆæ•°æ®è·å–ã€AIåˆ†æã€ç»“æœç”Ÿæˆçš„æ ¸å¿ƒå¼•æ“
"""

from typing import Dict, Any, List
from datetime import datetime, timedelta
import time
import logging

# å°è¯•å¤šç§å¯¼å…¥æ–¹å¼ä»¥å…¼å®¹ä¸åŒè¿è¡Œç¯å¢ƒ
try:
    # FastAPI ç¯å¢ƒ - ç»å¯¹å¯¼å…¥
    from app.data.longhubang_data import LonghubangDataFetcher
    from app.db.longhubang_db import LonghubangDatabase
    from app.agents.longhubang_agents import LonghubangAgents
    from app.services.longhubang.longhubang_scoring import LonghubangScoring
except ImportError:
    try:
        # Streamlit ç¯å¢ƒ - ç›¸å¯¹å¯¼å…¥
        from data.longhubang_data import LonghubangDataFetcher
        from db.longhubang_db import LonghubangDatabase
        from agents.longhubang_agents import LonghubangAgents
        from longhubang_scoring import LonghubangScoring
    except ImportError:
        # ç›´æ¥è¿è¡Œæ—¶çš„å¯¼å…¥
        import sys
        import os
        sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
        from data.longhubang_data import LonghubangDataFetcher
        from db.longhubang_db import LonghubangDatabase
        from agents.longhubang_agents import LonghubangAgents
        from longhubang_scoring import LonghubangScoring


class LonghubangService:
    """é¾™è™æ¦œç»¼åˆåˆ†æå¼•æ“"""
    
    def __init__(self, model="deepseek-chat", db_path=None):
        """
        åˆå§‹åŒ–åˆ†æå¼•æ“
        
        Args:
            model: AIæ¨¡å‹åç§°
            db_path: æ•°æ®åº“è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨ç»Ÿä¸€çš„sqlite_dbç›®å½•
        """
        self.data_fetcher = LonghubangDataFetcher()
        self.database = LonghubangDatabase(db_path)
        self.agents = LonghubangAgents(model=model)
        self.scoring = LonghubangScoring()
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s %(name)s: %(message)s')
        self.logger.info("[æ™ºç°é¾™è™] åˆ†æå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def run_comprehensive_analysis(self, date=None, days=1) -> Dict[str, Any]:
        """
      å®Œæ•´çš„é¾™è™æ¦œåˆ†ææµ  è¿è¡Œç¨‹
        
        Args:
            date: æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDï¼Œé»˜è®¤ä¸ºæ˜¨æ—¥
            days: åˆ†ææœ€è¿‘å‡ å¤©çš„æ•°æ®ï¼Œé»˜è®¤1å¤©
            
        Returns:
            å®Œæ•´çš„åˆ†æç»“æœ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ æ™ºç°é¾™è™ç»¼åˆåˆ†æç³»ç»Ÿå¯åŠ¨")
        self.logger.info("=" * 60)
        
        results = {
            "success": False,
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "data_info": {},
            "agents_analysis": {},
            "final_report": {},
            "recommended_stocks": []
        }
        
        try:
            # é˜¶æ®µ1: è·å–é¾™è™æ¦œæ•°æ®
            self.logger.info("[é˜¶æ®µ1] è·å–é¾™è™æ¦œæ•°æ®...")
            self.logger.info("-" * 60)
            
            if date:
                data_list = [self.data_fetcher.get_longhubang_data(date)]
                data_list = data_list[0].get('data', []) if data_list[0] else []
            else:
                data_list = self.data_fetcher.get_recent_days_data(days)
            
            if not data_list:
                self.logger.error("æœªè·å–åˆ°é¾™è™æ¦œæ•°æ®")
                results["error"] = "æœªè·å–åˆ°é¾™è™æ¦œæ•°æ®"
                return results

            self.logger.info(f"æˆåŠŸè·å– {len(data_list)} æ¡é¾™è™æ¦œè®°å½•")
            
            # é˜¶æ®µ2: ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
            self.logger.info("[é˜¶æ®µ2] ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...")
            self.logger.info("-" * 60)
            saved_count = self.database.save_longhubang_data(data_list)
            self.logger.info(f"ä¿å­˜ {saved_count} æ¡è®°å½•")
            
            # é˜¶æ®µ3: æ•°æ®åˆ†æå’Œç»Ÿè®¡
            self.logger.info("[é˜¶æ®µ3] æ•°æ®åˆ†æå’Œç»Ÿè®¡...")
            self.logger.info("-" * 60)
            summary = self.data_fetcher.analyze_data_summary(data_list)
            formatted_data = self.data_fetcher.format_data_for_ai(data_list, summary)
            
            results["data_info"] = {
                "total_records": summary.get('total_records', 0),
                "total_stocks": summary.get('total_stocks', 0),
                "total_youzi": summary.get('total_youzi', 0),
                "summary": summary
            }
            self.logger.info("æ•°æ®ç»Ÿè®¡å®Œæˆ")
            
            # é˜¶æ®µ3.5: AIæ™ºèƒ½è¯„åˆ†æ’å
            self.logger.info("[é˜¶æ®µ3.5] AIæ™ºèƒ½è¯„åˆ†æ’å...")
            self.logger.info("-" * 60)
            scoring_df = self.scoring.score_all_stocks(data_list)
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼ä»¥é¿å…UI/å­˜å‚¨ç±»å‹é—®é¢˜
            scoring_ranking_data: List[Dict[str, Any]] = []
            try:
                if scoring_df is not None and hasattr(scoring_df, 'to_dict'):
                    scoring_ranking_data = scoring_df.to_dict('records')
                    self.logger.info(f"å®Œæˆ {len(scoring_ranking_data)} åªè‚¡ç¥¨çš„æ™ºèƒ½è¯„åˆ†æ’å")
                else:
                    self.logger.warning("è¯„åˆ†ç»“æœä¸ºç©ºæˆ–æ ¼å¼ä¸æ”¯æŒè½¬æ¢")
            except Exception as e:
                self.logger.exception(f"è¯„åˆ†æ’åæ•°æ®è½¬æ¢å¤±è´¥: {e}", exc_info=True)
                scoring_ranking_data = []
            results["scoring_ranking"] = scoring_ranking_data
            
            # é˜¶æ®µ4: AIåˆ†æå¸ˆå›¢é˜Ÿåˆ†æ
            self.logger.info("[é˜¶æ®µ4] AIåˆ†æå¸ˆå›¢é˜Ÿå·¥ä½œä¸­...")
            self.logger.info("-" * 60)
            
            agents_results = {}
            
            # 1. æ¸¸èµ„è¡Œä¸ºåˆ†æå¸ˆ
            self.logger.info("1/5 æ¸¸èµ„è¡Œä¸ºåˆ†æå¸ˆ...")
            youzi_result = self.agents.youzi_behavior_analyst(formatted_data, summary)
            agents_results["youzi"] = youzi_result
            
            # 2. ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆ
            self.logger.info("2/5 ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆ...")
            stock_result = self.agents.stock_potential_analyst(formatted_data, summary)
            agents_results["stock"] = stock_result
            
            # 3. é¢˜æè¿½è¸ªåˆ†æå¸ˆ
            self.logger.info("3/5 é¢˜æè¿½è¸ªåˆ†æå¸ˆ...")
            theme_result = self.agents.theme_tracker_analyst(formatted_data, summary)
            agents_results["theme"] = theme_result
            
            # 4. é£é™©æ§åˆ¶ä¸“å®¶
            self.logger.info("4/5 é£é™©æ§åˆ¶ä¸“å®¶...")
            risk_result = self.agents.risk_control_specialist(formatted_data, summary)
            agents_results["risk"] = risk_result
            
            # 5. é¦–å¸­ç­–ç•¥å¸ˆç»¼åˆ
            self.logger.info("5/5 é¦–å¸­ç­–ç•¥å¸ˆç»¼åˆåˆ†æ...")
            all_analyses = [youzi_result, stock_result, theme_result, risk_result]
            chief_result = self.agents.chief_strategist(all_analyses)
            agents_results["chief"] = chief_result
            
            results["agents_analysis"] = agents_results
            self.logger.info("æ‰€æœ‰AIåˆ†æå¸ˆåˆ†æå®Œæˆ")
            
            # é˜¶æ®µ5: æå–æ¨èè‚¡ç¥¨
            self.logger.info("[é˜¶æ®µ5] æå–æ¨èè‚¡ç¥¨...")
            self.logger.info("-" * 60)
            recommended_stocks = self._extract_recommended_stocks(
                chief_result.get('analysis', ''),
                stock_result.get('analysis', ''),
                summary
            )
            results["recommended_stocks"] = recommended_stocks
            self.logger.info(f"æå– {len(recommended_stocks)} åªæ¨èè‚¡ç¥¨")
            
            # é˜¶æ®µ6: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            self.logger.info("[é˜¶æ®µ6] ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
            self.logger.info("-" * 60)
            final_report = self._generate_final_report(agents_results, summary, recommended_stocks)
            results["final_report"] = final_report
            self.logger.info("æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            
            # é˜¶æ®µ7: ä¿å­˜å®Œæ•´åˆ†ææŠ¥å‘Šåˆ°æ•°æ®åº“
            self.logger.info("[é˜¶æ®µ7] ä¿å­˜å®Œæ•´åˆ†ææŠ¥å‘Š...")
            self.logger.info("-" * 60)
            data_date_range = self._get_date_range(data_list)
            
            # è½¬æ¢è¯„åˆ†æ’åæ•°æ®ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
            # å¤ç”¨å‰é¢è½¬æ¢çš„è¯„åˆ†æ•°æ®
            # è‹¥å‰é¢è½¬æ¢å¤±è´¥ï¼Œæ­¤å¤„ä¸å†é‡å¤è½¬æ¢ï¼Œé¿å…é”™è¯¯
            
            # æ„å»ºå®Œæ•´çš„åˆ†æå†…å®¹ï¼ˆç»“æ„åŒ–ï¼‰
            full_analysis_content = {
                "agents_analysis": agents_results,
                "data_info": results["data_info"],
                "scoring_ranking": scoring_ranking_data,
                "final_report": final_report,
                "timestamp": results["timestamp"]
            }
            
            report_id = self.database.save_analysis_report(
                data_date_range=data_date_range,
                analysis_content=full_analysis_content,  # ä¿å­˜å®Œæ•´çš„ç»“æ„åŒ–æ•°æ®
                recommended_stocks=recommended_stocks,
                summary=final_report.get('summary', ''),
                full_result=results  # ä¼ å…¥å®Œæ•´ç»“æœ
            )
            results["report_id"] = report_id
            self.logger.info(f"å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜ (ID: {report_id})")
            
            results["success"] = True
            
            self.logger.info("=" * 60)
            self.logger.info("âœ“ æ™ºç°é¾™è™ç»¼åˆåˆ†æå®Œæˆï¼")
            self.logger.info("=" * 60)
            
        except Exception as e:
            self.logger.exception(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}", exc_info=True)
            results["error"] = str(e)

        return results
    
    def _extract_recommended_stocks(self, chief_analysis: str, stock_analysis: str, summary: Dict) -> List[Dict]:
        """
        ä»AIåˆ†æä¸­æå–æ¨èè‚¡ç¥¨
        
        æ”¯æŒè§£ææ ¼å¼ï¼š
        1. é¦–å¸­åˆ†æå¸ˆ Markdown è¡¨æ ¼: | ä¼˜å…ˆçº§ | è‚¡ç¥¨åç§° (ä»£ç ) | æ¨èç†ç”± | ç¡®å®šæ€§è¯„çº§ | ä¹°å…¥ä»·ä½åŒºé—´ | ç›®æ ‡ä»·ä½ | æ­¢æŸä»·ä½ | æŒæœ‰å‘¨æœŸå»ºè®® |
        2. ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆæ ‡é¢˜æ ¼å¼: #### **1.1 çº¢ç›¸è‚¡ä»½ (300290)**
        
        Args:
            chief_analysis: é¦–å¸­ç­–ç•¥å¸ˆåˆ†æ
            stock_analysis: ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆåˆ†æ
            summary: æ•°æ®æ‘˜è¦
            
        Returns:
            æ¨èè‚¡ç¥¨åˆ—è¡¨
        """
        import re
        
        recommended = []
        seen_codes = set()
        
        # ä»æ‘˜è¦ä¸­è·å–TOPè‚¡ç¥¨ä½œä¸ºåŸºç¡€æ•°æ®
        top_stocks_map = {}
        if summary.get('top_stocks'):
            for stock in summary['top_stocks']:
                code = stock.get('code', '')
                top_stocks_map[code] = stock
        
        # ========== æ–¹æ³•1: è§£æé¦–å¸­åˆ†æå¸ˆçš„ Markdown è¡¨æ ¼ ==========
        if chief_analysis:
            # åŒ¹é…è¡¨æ ¼è¡Œ: | **1** | **è£ç§‘ç§‘æŠ€ (300290)** | æ¨èç†ç”±... | **é«˜** | ä»·ä½åŒºé—´ | ç›®æ ‡ä»· | æ­¢æŸä»· | å‘¨æœŸ |
            table_pattern = r'\|\s*\**(\d+)\**\s*\|\s*\**([^|ï¼ˆ(]+)[ï¼ˆ(](\d{6})[ï¼‰)]\**\s*\|\s*([^|]+)\|\s*\**([^|*]+)\**\s*\|\s*([^|]+)\|\s*([^|]+)\|\s*([^|]+)\|\s*([^|]+)\|'
            table_matches = re.findall(table_pattern, chief_analysis)
            
            for match in table_matches:
                try:
                    rank = int(match[0])
                    name = match[1].strip(' *')
                    code = match[2]
                    reason = match[3].strip()
                    confidence = match[4].strip()
                    buy_price = match[5].strip()
                    target_price = match[6].strip()
                    stop_loss = match[7].strip()
                    hold_period = match[8].strip()
                    
                    if code not in seen_codes:
                        seen_codes.add(code)
                        base_data = top_stocks_map.get(code, {})
                        net_inflow = base_data.get('net_inflow', 0)
                        
                        # æå–æ¸¸èµ„å’Œé£æ ¼ä¿¡æ¯
                        youzi = ''
                        youzi_style = ''
                        # ä»ç†ç”±ä¸­æå–æ¸¸èµ„ä¿¡æ¯
                        youzi_match = re.search(r'(æˆéƒ½ç³»|è‹å—å¸®|é‡åŒ–æ‰“æ¿|ç‘é¹¤ä»™|ç‚’è‚¡å…»å®¶|å®æ³¢æ¡‘ç”°è·¯|æ¬¢ä¹æµ·å²¸|æ·±è‚¡é€š|æ²ªè‚¡é€š|æœºæ„)', reason)
                        if youzi_match:
                            youzi = youzi_match.group(1)
                            youzi_style = 'çŸ­çº¿æ¸¸èµ„' if youzi in ['æˆéƒ½ç³»', 'è‹å—å¸®', 'é‡åŒ–æ‰“æ¿', 'ç‘é¹¤ä»™', 'ç‚’è‚¡å…»å®¶', 'å®æ³¢æ¡‘ç”°è·¯'] else 'æœºæ„èµ„é‡‘'
                        
                        # æå–æ ‡ç­¾
                        tags = []
                        tag_keywords = ['AI', 'äººå·¥æ™ºèƒ½', 'ä¿¡åˆ›', 'å†›å·¥', 'å›½ä¼', 'å¤®å›½ä¼', 'æ•°æ®è¦ç´ ', 'åä¸º', 'æœºå™¨äºº', 'åŒ»è¯', 'å…‰æ¨¡å—']
                        for kw in tag_keywords:
                            if kw in reason:
                                tags.append(kw)
                        tags = tags[:3]  # æœ€å¤š3ä¸ªæ ‡ç­¾
                        
                        # æå–é£é™©æç¤º
                        risk = ''
                        risk_match = re.search(r'é£é™©[ï¼š:åœ¨äº]([^ã€‚]+)', reason)
                        if risk_match:
                            risk = risk_match.group(1).strip()
                        if not risk:
                            risk = 'æ³¨æ„ä»“ä½æ§åˆ¶ï¼Œä¸¥æ ¼æ‰§è¡Œæ­¢æŸ'
                        
                        recommended.append({
                            'rank': rank,
                            'code': code,
                            'name': name,
                            'net_inflow': net_inflow,
                            'reason': reason[:200] if len(reason) > 200 else reason,
                            'confidence': confidence,
                            'buy_price': buy_price,
                            'target_price': target_price,
                            'stop_loss': stop_loss,
                            'hold_period': hold_period,
                            'source': 'chief',
                            'youzi': youzi,
                            'youzi_style': youzi_style,
                            'tags': tags,
                            'risk': risk
                        })
                except Exception as e:
                    self.logger.warning(f"è§£æè¡¨æ ¼è¡Œå¤±è´¥: {e}")
                    continue
        
        # ========== æ–¹æ³•2: è§£æä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆçš„æ ‡é¢˜æ ¼å¼ ==========
        if stock_analysis and len(recommended) < 10:
            # åŒ¹é…æ ‡é¢˜: #### **1.1 çº¢ç›¸è‚¡ä»½ (300290)**
            title_pattern = r'####\s*\**\d+\.\d+\s+([^ï¼ˆ(]+)[ï¼ˆ(](\d{6})[ï¼‰)]'
            title_matches = re.findall(title_pattern, stock_analysis)
            
            for name, code in title_matches:
                name = name.strip(' *')
                if code not in seen_codes:
                    seen_codes.add(code)
                    base_data = top_stocks_map.get(code, {})
                    net_inflow = base_data.get('net_inflow', 0)
                    
                    # æå–è¯¥è‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
                    stock_info = self._extract_stock_detail_from_analyst(stock_analysis, name, code)
                    
                    recommended.append({
                        'rank': len(recommended) + 1,
                        'code': code,
                        'name': name,
                        'net_inflow': net_inflow,
                        'reason': stock_info.get('reason', f'ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆæ¨è'),
                        'confidence': stock_info.get('confidence', 'ä¸­'),
                        'buy_price': stock_info.get('buy_price', 'å¾…å®š'),
                        'target_price': stock_info.get('target_price', 'å¾…å®š'),
                        'stop_loss': stock_info.get('stop_loss', 'å¾…å®š'),
                        'hold_period': stock_info.get('hold_period', 'çŸ­çº¿'),
                        'source': 'stock_analyst',
                        'youzi': stock_info.get('youzi', ''),
                        'youzi_style': stock_info.get('youzi_style', ''),
                        'tags': stock_info.get('tags', []),
                        'risk': stock_info.get('risk', 'æ³¨æ„ä»“ä½æ§åˆ¶')
                    })
                    
                    if len(recommended) >= 10:
                        break
        
        # ========== æ–¹æ³•3: é€šç”¨æ­£åˆ™åŒ¹é…ä½œä¸ºå…œåº• ==========
        if len(recommended) < 5:
            combined_text = (chief_analysis or '') + '\n' + (stock_analysis or '')
            # åŒ¹é…: è‚¡ç¥¨åç§° (ä»£ç ) æˆ– è‚¡ç¥¨åç§°ï¼ˆä»£ç ï¼‰
            stock_pattern = r'\*{0,2}([^\d\s\(\)ï¼ˆï¼‰|*]{2,6})\s*[ï¼ˆ(](\d{6})[ï¼‰)]\*{0,2}'
            matches = re.findall(stock_pattern, combined_text)
            
            for name, code in matches:
                name = name.strip(' *Â·ã€ï¼Œã€‚ï¼š:')
                if code not in seen_codes and len(name) >= 2 and len(name) <= 6:
                    seen_codes.add(code)
                    base_data = top_stocks_map.get(code, {})
                    net_inflow = base_data.get('net_inflow', 0)
                    
                    recommended.append({
                        'rank': len(recommended) + 1,
                        'code': code,
                        'name': name,
                        'net_inflow': net_inflow,
                        'reason': f'AIåˆ†æå¸ˆæ¨èï¼Œèµ„é‡‘å‡€æµå…¥ {net_inflow:,.0f} å…ƒ' if net_inflow else 'AIåˆ†æå¸ˆæ¨è',
                        'confidence': 'ä¸­',
                        'buy_price': 'å¾…å®š',
                        'target_price': 'å¾…å®š',
                        'stop_loss': 'å¾…å®š',
                        'hold_period': 'çŸ­çº¿',
                        'source': 'ai_analysis',
                        'youzi': '',
                        'youzi_style': '',
                        'tags': [],
                        'risk': 'æ³¨æ„ä»“ä½æ§åˆ¶'
                    })
                    
                    if len(recommended) >= 10:
                        break
        
        # ========== è¡¥å……æ‘˜è¦ä¸­çš„TOPè‚¡ç¥¨ ==========
        if len(recommended) < 5 and summary.get('top_stocks'):
            for stock in summary['top_stocks']:
                code = stock['code']
                if code not in seen_codes:
                    seen_codes.add(code)
                    recommended.append({
                        'rank': len(recommended) + 1,
                        'code': code,
                        'name': stock['name'],
                        'net_inflow': stock['net_inflow'],
                        'reason': f"èµ„é‡‘å‡€æµå…¥ TOP è‚¡ç¥¨ï¼Œå‡€æµå…¥ {stock['net_inflow']:,.0f} å…ƒ",
                        'confidence': 'ä¸­',
                        'buy_price': 'å¾…å®š',
                        'target_price': 'å¾…å®š',
                        'stop_loss': 'å¾…å®š',
                        'hold_period': 'çŸ­çº¿',
                        'source': 'summary',
                        'youzi': '',
                        'youzi_style': '',
                        'tags': [],
                        'risk': 'æ³¨æ„ä»“ä½æ§åˆ¶'
                    })
                    if len(recommended) >= 10:
                        break
        
        # é‡æ–°æ’åº
        for idx, stock in enumerate(recommended, 1):
            stock['rank'] = idx
        
        self.logger.info(f"[æ™ºç°é¾™è™] ä»AIåˆ†æä¸­æå–äº† {len(recommended)} åªæ¨èè‚¡ç¥¨")
        
        return recommended
    
    def _extract_stock_detail_from_analyst(self, text: str, stock_name: str, stock_code: str) -> Dict:
        """
        ä»ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆæ–‡æœ¬ä¸­æå–å•åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            text: åˆ†æå¸ˆå®Œæ•´æ–‡æœ¬
            stock_name: è‚¡ç¥¨åç§°
            stock_code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            åŒ…å«è¯¦ç»†ä¿¡æ¯çš„å­—å…¸
        """
        import re
        
        info = {
            'reason': '',
            'confidence': 'ä¸­',
            'buy_price': 'å¾…å®š',
            'target_price': 'å¾…å®š',
            'stop_loss': 'å¾…å®š',
            'hold_period': 'çŸ­çº¿',
            'youzi': '',
            'youzi_style': '',
            'tags': [],
            'risk': 'æ³¨æ„ä»“ä½æ§åˆ¶'
        }
        
        # æŸ¥æ‰¾è¯¥è‚¡ç¥¨çš„åˆ†ææ®µè½ï¼ˆä»æ ‡é¢˜åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜æˆ–åˆ†éš”çº¿ï¼‰
        pattern = rf'####\s*\**\d+\.\d+\s+{re.escape(stock_name)}\s*[ï¼ˆ(]{stock_code}[ï¼‰)].*?(?=####|\Z|---)'
        match = re.search(pattern, text, re.DOTALL)
        
        if not match:
            return info
        
        section = match.group(0)
        
        # æå–ä¸Šæ¶¨é€»è¾‘ä½œä¸ºæ¨èç†ç”±
        logic_match = re.search(r'\*\*ä¸Šæ¶¨é€»è¾‘[ï¼š:]\*\*([^*]+)', section)
        if logic_match:
            info['reason'] = logic_match.group(1).strip()[:200]
        else:
            # å°è¯•æå–èµ„é‡‘é¢æè¿°
            fund_match = re.search(r'\*\*èµ„é‡‘é¢[ï¼ˆ(][^)ï¼‰]+[)ï¼‰][ï¼š:]\*\*([^*]+)', section)
            if fund_match:
                info['reason'] = fund_match.group(1).strip()[:200]
        
        # æå–ç¡®å®šæ€§
        conf_match = re.search(r'\*\*([é«˜ä¸­ä½]+)ç¡®å®šæ€§', section)
        if conf_match:
            info['confidence'] = conf_match.group(1)
        
        # æå–ä¹°å…¥ä»·ä½
        buy_match = re.search(r'\*\*ä¹°å…¥ä»·ä½[ï¼š:]\*\*\s*([^\n*]+)', section)
        if buy_match:
            info['buy_price'] = buy_match.group(1).strip()
        else:
            # å°è¯•å…¶ä»–æ ¼å¼
            buy_match2 = re.search(r'é«˜å¼€[åœ¨]?(\d+%?)[ä»¥]?å†…|å¹³å¼€|å°å¹…[é«˜ä½]å¼€', section)
            if buy_match2:
                info['buy_price'] = buy_match2.group(0)
        
        # æå–æ­¢æŸä»·ä½
        stop_match = re.search(r'\*\*æ­¢æŸä½[ï¼š:]\*\*\s*([^\n*]+)', section)
        if stop_match:
            info['stop_loss'] = stop_match.group(1).strip()
        
        # æå–ç›®æ ‡ä»·ä½
        target_match = re.search(r'\+(\d+%?è‡³\+?\d+%?)', section)
        if target_match:
            info['target_price'] = target_match.group(1)
        
        # æå–æŒæœ‰å‘¨æœŸ
        if 'è¶…çŸ­çº¿' in section or '1-3å¤©' in section:
            info['hold_period'] = 'è¶…çŸ­çº¿(1-3å¤©)'
        elif 'çŸ­çº¿' in section or '3-5å¤©' in section:
            info['hold_period'] = 'çŸ­çº¿(3-5å¤©)'
        elif 'æ³¢æ®µ' in section:
            info['hold_period'] = 'æ³¢æ®µ'
        
        # æå–æ¸¸èµ„ä¿¡æ¯
        youzi_keywords = ['æˆéƒ½ç³»', 'è‹å—å¸®', 'é‡åŒ–æ‰“æ¿', 'ç‘é¹¤ä»™', 'ç‚’è‚¡å…»å®¶', 'å®æ³¢æ¡‘ç”°è·¯', 'æ¬¢ä¹æµ·å²¸', 'æ·±è‚¡é€š', 'æ²ªè‚¡é€š', 'æœºæ„ä¸“ç”¨']
        for kw in youzi_keywords:
            if kw in section:
                info['youzi'] = kw
                info['youzi_style'] = 'çŸ­çº¿æ¸¸èµ„' if kw in ['æˆéƒ½ç³»', 'è‹å—å¸®', 'é‡åŒ–æ‰“æ¿', 'ç‘é¹¤ä»™', 'ç‚’è‚¡å…»å®¶', 'å®æ³¢æ¡‘ç”°è·¯'] else 'æœºæ„èµ„é‡‘'
                break
        
        # æå–æ ‡ç­¾
        tag_keywords = ['AI', 'äººå·¥æ™ºèƒ½', 'ä¿¡åˆ›', 'å†›å·¥', 'å›½ä¼', 'å¤®å›½ä¼', 'æ•°æ®è¦ç´ ', 'åä¸º', 'æœºå™¨äºº', 'åŒ»è¯', 'å…‰æ¨¡å—', 'ç”µç½‘', 'ç‰©è”ç½‘']
        for kw in tag_keywords:
            if kw in section and kw not in info['tags']:
                info['tags'].append(kw)
        info['tags'] = info['tags'][:3]
        
        # æå–é£é™©æç¤º
        risk_match = re.search(r'é£é™©[åœ¨äºæç¤ºï¼š:]+([^ã€‚\n]+)', section)
        if risk_match:
            info['risk'] = risk_match.group(1).strip()
        
        return info
    
    def _generate_final_report(self, agents_results: Dict, summary: Dict, 
                               recommended_stocks: List[Dict]) -> Dict:
        """
        ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        
        Args:
            agents_results: æ‰€æœ‰åˆ†æå¸ˆçš„åˆ†æç»“æœ
            summary: æ•°æ®æ‘˜è¦
            recommended_stocks: æ¨èè‚¡ç¥¨åˆ—è¡¨
            
        Returns:
            æœ€ç»ˆæŠ¥å‘Šå­—å…¸
        """
        report = {
            'title': 'æ™ºç°é¾™è™æ¦œç»¼åˆåˆ†ææŠ¥å‘Š',
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'summary': '',
            'data_overview': {
                'total_records': summary.get('total_records', 0),
                'total_stocks': summary.get('total_stocks', 0),
                'total_youzi': summary.get('total_youzi', 0),
                'total_net_inflow': summary.get('total_net_inflow', 0)
            },
            'recommended_stocks_count': len(recommended_stocks),
            'agents_count': len(agents_results)
        }
        
        # ç”Ÿæˆæ‘˜è¦
        summary_parts = []
        summary_parts.append(f"æœ¬æ¬¡åˆ†æå…±æ¶µç›– {summary.get('total_records', 0)} æ¡é¾™è™æ¦œè®°å½•")
        summary_parts.append(f"æ¶‰åŠ {summary.get('total_stocks', 0)} åªè‚¡ç¥¨")
        summary_parts.append(f"æ¶‰åŠ {summary.get('total_youzi', 0)} ä¸ªæ¸¸èµ„å¸­ä½")
        summary_parts.append(f"å…±æ¨è {len(recommended_stocks)} åªæ½œåŠ›è‚¡ç¥¨")
        
        report['summary'] = "ï¼Œ".join(summary_parts) + "ã€‚"
        
        return report
    
    def _get_date_range(self, data_list: List[Dict]) -> str:
        """
        è·å–æ•°æ®çš„æ—¥æœŸèŒƒå›´
        
        Args:
            data_list: æ•°æ®åˆ—è¡¨
            
        Returns:
            æ—¥æœŸèŒƒå›´å­—ç¬¦ä¸²
        """
        if not data_list:
            return "æœªçŸ¥"
        
        dates = []
        for record in data_list:
            date = record.get('rq') or record.get('æ—¥æœŸ')
            if date:
                dates.append(date)
        
        if not dates:
            return "æœªçŸ¥"
        
        dates = sorted(set(dates))
        if len(dates) == 1:
            return dates[0]
        else:
            return f"{dates[0]} è‡³ {dates[-1]}"
    
    def get_historical_reports(self, limit=10):
        """
        è·å–å†å²åˆ†ææŠ¥å‘Š
        
        Args:
            limit: è¿”å›æ•°é‡
            
        Returns:
            æŠ¥å‘Šåˆ—è¡¨
        """
        return self.database.get_analysis_reports(limit)
    
    def get_report_detail(self, report_id):
        """
        è·å–æŠ¥å‘Šè¯¦æƒ…
        
        Args:
            report_id: æŠ¥å‘ŠID
            
        Returns:
            æŠ¥å‘Šè¯¦æƒ…
        """
        return self.database.get_analysis_report(report_id)
    
    def get_statistics(self):
        """
        è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        return self.database.get_statistics()
    
    def get_top_youzi(self, start_date=None, end_date=None, limit=20):
        """
        è·å–æ´»è·ƒæ¸¸èµ„æ’å
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            limit: è¿”å›æ•°é‡
            
        Returns:
            æ¸¸èµ„æ’å
        """
        return self.database.get_top_youzi(start_date, end_date, limit)
    
    def get_top_stocks(self, start_date=None, end_date=None, limit=20):
        """
        è·å–çƒ­é—¨è‚¡ç¥¨æ’å
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            limit: è¿”å›æ•°é‡
            
        Returns:
            è‚¡ç¥¨æ’å
        """
        return self.database.get_top_stocks(start_date, end_date, limit)
    
    def run_comprehensive_analysis_with_progress(
        self, 
        date=None, 
        days=1,
        progress_callback=None,
        log_callback=None
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„é¾™è™æ¦œåˆ†ææµç¨‹ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
        
        Args:
            date: æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDï¼Œé»˜è®¤ä¸ºæ˜¨æ—¥
            days: åˆ†ææœ€è¿‘å‡ å¤©çš„æ•°æ®ï¼Œé»˜è®¤1å¤©
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (progress: int, message: str, stage: str)
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•° (level: str, message: str)
            
        Returns:
            å®Œæ•´çš„åˆ†æç»“æœ
        """
        def _progress(progress: int, message: str, stage: str = ""):
            self.logger.info(f"[{progress}%] {message}")
            if progress_callback:
                progress_callback(progress, message, stage)
        
        def _log(level: str, message: str):
            if level == "info":
                self.logger.info(message)
            elif level == "warning":
                self.logger.warning(message)
            elif level == "error":
                self.logger.error(message)
            if log_callback:
                log_callback(level, message)
        
        _progress(0, "ğŸš€ æ™ºç°é¾™è™ç»¼åˆåˆ†æç³»ç»Ÿå¯åŠ¨", "init")
        
        results = {
            "success": False,
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "data_info": {},
            "agents_analysis": {},
            "final_report": {},
            "recommended_stocks": []
        }
        
        try:
            # é˜¶æ®µ1: è·å–é¾™è™æ¦œæ•°æ®
            _progress(5, "ğŸ“Š æ­£åœ¨è·å–é¾™è™æ¦œæ•°æ®...", "fetch_data")
            
            if date:
                data_result = self.data_fetcher.get_longhubang_data(date)
                data_list = data_result.get('data', []) if data_result else []
            else:
                data_list = self.data_fetcher.get_recent_days_data(days)
            
            if not data_list:
                _log("error", "æœªè·å–åˆ°é¾™è™æ¦œæ•°æ®")
                results["error"] = "æœªè·å–åˆ°é¾™è™æ¦œæ•°æ®"
                return results

            _log("info", f"æˆåŠŸè·å– {len(data_list)} æ¡é¾™è™æ¦œè®°å½•")
            _progress(10, f"âœ“ è·å–åˆ° {len(data_list)} æ¡è®°å½•", "fetch_data")
            
            # é˜¶æ®µ2: ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
            _progress(12, "ğŸ’¾ ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...", "save_data")
            saved_count = self.database.save_longhubang_data(data_list)
            _log("info", f"ä¿å­˜ {saved_count} æ¡è®°å½•")
            _progress(15, f"âœ“ ä¿å­˜ {saved_count} æ¡è®°å½•", "save_data")
            
            # é˜¶æ®µ3: æ•°æ®åˆ†æå’Œç»Ÿè®¡
            _progress(18, "ğŸ“ˆ æ•°æ®åˆ†æå’Œç»Ÿè®¡...", "analyze_data")
            summary = self.data_fetcher.analyze_data_summary(data_list)
            formatted_data = self.data_fetcher.format_data_for_ai(data_list, summary)
            
            results["data_info"] = {
                "total_records": summary.get('total_records', 0),
                "total_stocks": summary.get('total_stocks', 0),
                "total_youzi": summary.get('total_youzi', 0),
                "summary": summary
            }
            _progress(22, "âœ“ æ•°æ®ç»Ÿè®¡å®Œæˆ", "analyze_data")
            
            # é˜¶æ®µ3.5: AIæ™ºèƒ½è¯„åˆ†æ’å
            _progress(25, "ğŸ† AIæ™ºèƒ½è¯„åˆ†æ’å...", "scoring")
            scoring_df = self.scoring.score_all_stocks(data_list)
            scoring_ranking_data: List[Dict[str, Any]] = []
            try:
                if scoring_df is not None and hasattr(scoring_df, 'to_dict'):
                    scoring_ranking_data = scoring_df.to_dict('records')
                    _log("info", f"å®Œæˆ {len(scoring_ranking_data)} åªè‚¡ç¥¨çš„æ™ºèƒ½è¯„åˆ†æ’å")
            except Exception as e:
                _log("warning", f"è¯„åˆ†æ’åæ•°æ®è½¬æ¢å¤±è´¥: {e}")
            results["scoring_ranking"] = scoring_ranking_data
            _progress(30, f"âœ“ å®Œæˆ {len(scoring_ranking_data)} åªè‚¡ç¥¨è¯„åˆ†", "scoring")
            
            # é˜¶æ®µ4: AIåˆ†æå¸ˆå›¢é˜Ÿåˆ†æ
            _progress(32, "ğŸ¤– AIåˆ†æå¸ˆå›¢é˜Ÿå¼€å§‹å·¥ä½œ...", "ai_analysis")
            agents_results = {}
            
            # 1. æ¸¸èµ„è¡Œä¸ºåˆ†æå¸ˆ
            _progress(35, "ğŸ¯ æ¸¸èµ„è¡Œä¸ºåˆ†æå¸ˆæ­£åœ¨åˆ†æ...", "agent_youzi")
            _log("info", "1/5 æ¸¸èµ„è¡Œä¸ºåˆ†æå¸ˆ...")
            youzi_result = self.agents.youzi_behavior_analyst(formatted_data, summary)
            agents_results["youzi"] = youzi_result
            _progress(45, "âœ“ æ¸¸èµ„è¡Œä¸ºåˆ†æå®Œæˆ", "agent_youzi")
            
            # 2. ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆ
            _progress(47, "ğŸ“ˆ ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆæ­£åœ¨åˆ†æ...", "agent_stock")
            _log("info", "2/5 ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆ...")
            stock_result = self.agents.stock_potential_analyst(formatted_data, summary)
            agents_results["stock"] = stock_result
            _progress(55, "âœ“ ä¸ªè‚¡æ½œåŠ›åˆ†æå®Œæˆ", "agent_stock")
            
            # 3. é¢˜æè¿½è¸ªåˆ†æå¸ˆ
            _progress(57, "ğŸ”¥ é¢˜æè¿½è¸ªåˆ†æå¸ˆæ­£åœ¨åˆ†æ...", "agent_theme")
            _log("info", "3/5 é¢˜æè¿½è¸ªåˆ†æå¸ˆ...")
            theme_result = self.agents.theme_tracker_analyst(formatted_data, summary)
            agents_results["theme"] = theme_result
            _progress(65, "âœ“ é¢˜æè¿½è¸ªåˆ†æå®Œæˆ", "agent_theme")
            
            # 4. é£é™©æ§åˆ¶ä¸“å®¶
            _progress(67, "âš ï¸ é£é™©æ§åˆ¶ä¸“å®¶æ­£åœ¨åˆ†æ...", "agent_risk")
            _log("info", "4/5 é£é™©æ§åˆ¶ä¸“å®¶...")
            risk_result = self.agents.risk_control_specialist(formatted_data, summary)
            agents_results["risk"] = risk_result
            _progress(75, "âœ“ é£é™©æ§åˆ¶åˆ†æå®Œæˆ", "agent_risk")
            
            # 5. é¦–å¸­ç­–ç•¥å¸ˆç»¼åˆ
            _progress(77, "ğŸ‘” é¦–å¸­ç­–ç•¥å¸ˆç»¼åˆåˆ†æ...", "agent_chief")
            _log("info", "5/5 é¦–å¸­ç­–ç•¥å¸ˆç»¼åˆåˆ†æ...")
            all_analyses = [youzi_result, stock_result, theme_result, risk_result]
            chief_result = self.agents.chief_strategist(all_analyses)
            agents_results["chief"] = chief_result
            _progress(85, "âœ“ é¦–å¸­ç­–ç•¥å¸ˆåˆ†æå®Œæˆ", "agent_chief")
            
            results["agents_analysis"] = agents_results
            _log("info", "æ‰€æœ‰AIåˆ†æå¸ˆåˆ†æå®Œæˆ")
            
            # é˜¶æ®µ5: æå–æ¨èè‚¡ç¥¨
            _progress(87, "ğŸ¯ æå–æ¨èè‚¡ç¥¨...", "extract_stocks")
            recommended_stocks = self._extract_recommended_stocks(
                chief_result.get('analysis', ''),
                stock_result.get('analysis', ''),
                summary
            )
            results["recommended_stocks"] = recommended_stocks
            _progress(90, f"âœ“ æå– {len(recommended_stocks)} åªæ¨èè‚¡ç¥¨", "extract_stocks")
            
            # é˜¶æ®µ6: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            _progress(92, "ğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...", "generate_report")
            final_report = self._generate_final_report(agents_results, summary, recommended_stocks)
            results["final_report"] = final_report
            _progress(95, "âœ“ æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ", "generate_report")
            
            # é˜¶æ®µ7: ä¿å­˜å®Œæ•´åˆ†ææŠ¥å‘Šåˆ°æ•°æ®åº“
            _progress(97, "ğŸ’¾ ä¿å­˜åˆ†ææŠ¥å‘Š...", "save_report")
            data_date_range = self._get_date_range(data_list)
            
            full_analysis_content = {
                "agents_analysis": agents_results,
                "data_info": results["data_info"],
                "scoring_ranking": scoring_ranking_data,
                "final_report": final_report,
                "timestamp": results["timestamp"]
            }
            
            report_id = self.database.save_analysis_report(
                data_date_range=data_date_range,
                analysis_content=full_analysis_content,
                recommended_stocks=recommended_stocks,
                summary=final_report.get('summary', ''),
                full_result=results
            )
            results["report_id"] = report_id
            _log("info", f"å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜ (ID: {report_id})")
            
            results["success"] = True
            _progress(100, "ğŸ‰ æ™ºç°é¾™è™ç»¼åˆåˆ†æå®Œæˆï¼", "complete")
            
        except Exception as e:
            _log("error", f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            results["error"] = str(e)
            import traceback
            _log("error", traceback.format_exc())

        return results


# æµ‹
if __name__ == "__main__":
    print("=" * 60)
    print("æµ‹è¯•æ™ºç°é¾™è™åˆ†æå¼•æ“")
    print("=" * 60)
    
    # åˆ›å»ºå¼•æ“å®ä¾‹
    engine = LonghubangEngine()
    
    # è¿è¡Œç»¼åˆåˆ†æï¼ˆåˆ†ææ˜¨å¤©çš„æ•°æ®ï¼‰
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    results = engine.run_comprehensive_analysis(date=yesterday)
    
    if results.get('success'):
        print("\n" + "=" * 60)
        print("åˆ†ææˆåŠŸï¼")
        print("=" * 60)
        print(f"æ•°æ®è®°å½•: {results['data_info']['total_records']}")
        print(f"æ¶‰åŠè‚¡ç¥¨: {results['data_info']['total_stocks']}")
        print(f"æ¨èè‚¡ç¥¨: {len(results['recommended_stocks'])}")
    else:
        print(f"\nåˆ†æå¤±è´¥: {results.get('error', 'æœªçŸ¥é”™è¯¯')}")

